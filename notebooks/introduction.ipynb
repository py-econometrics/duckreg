{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `duckreg`: Out-of-memory regressions with `duckdb`\n",
    "\n",
    "Remember to carefully examine the underlying queries that generate the data; the package merely passes it into `np.linalg.lstsq` to solve the least squares problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from duckreg.estimators import DuckRegression\n",
    "import duckdb\n",
    "import pyfixest as pf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with discrete covariates\n",
    "\n",
    "The largest gains from compression arise when the right hand side variables are discrete, which is also the setting where linearity is an innocuous assumption (especially when the RHS is saturated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "def generate_sample_data(N=10_000_000, seed=12345):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    D = rng.choice([0, 1], size=(N, 1))\n",
    "    X = rng.choice(range(20), (N, 2), True)\n",
    "    Y = D + X @ np.array([1, 2]).reshape(2, 1) + rng.normal(size=(N, 1))\n",
    "    Y2 = -1 * D + X @ np.array([1, 2]).reshape(2, 1) + rng.normal(size=(N, 1))\n",
    "    df = pd.DataFrame(\n",
    "        np.concatenate([Y, Y2, D, X], axis=1), columns=[\"Y\", \"Y2\", \"D\", \"f1\", \"f2\"]\n",
    "    ).assign(rowid=range(N))\n",
    "    return df\n",
    "\n",
    "\n",
    "# Function to create and populate DuckDB database\n",
    "def create_duckdb_database(df, db_name=\"large_dataset.db\", table=\"data\"):\n",
    "    conn = duckdb.connect(db_name)\n",
    "    conn.execute(f\"DROP TABLE IF EXISTS {table}\")\n",
    "    conn.execute(f\"CREATE TABLE {table} AS SELECT * FROM df\")\n",
    "    conn.close()\n",
    "    print(f\"Data loaded into DuckDB database: {db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into DuckDB database: large_dataset.db\n"
     ]
    }
   ],
   "source": [
    "# Generate and save data\n",
    "df = generate_sample_data()\n",
    "db_name = \"large_dataset.db\"\n",
    "create_duckdb_database(df, db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the dataset. This dataset could be unreasonably large, which prevents the use of conventional in-memory regression techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>Y2</th>\n",
       "      <th>D</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>rowid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.226866</td>\n",
       "      <td>24.444717</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.088713</td>\n",
       "      <td>35.392007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.472292</td>\n",
       "      <td>21.185366</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.842856</td>\n",
       "      <td>38.012720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.136978</td>\n",
       "      <td>22.168634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Y         Y2    D    f1    f2  rowid\n",
       "0  27.226866  24.444717  1.0  16.0   5.0      0\n",
       "1  35.088713  35.392007  0.0   1.0  17.0      1\n",
       "2  22.472292  21.185366  1.0   6.0   8.0      2\n",
       "3  39.842856  38.012720  0.0   9.0  15.0      3\n",
       "4  23.136978  22.168634  0.0  10.0   6.0      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_name = \"large_dataset.db\"\n",
    "conn = duckdb.connect(db_name)\n",
    "query = \"SELECT * FROM data limit 5\"\n",
    "conn.execute(query).fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core idea of compressed representations is to retain the minimal set of sufficient statistics to compute the point estimate and variance-covariance matrix. We first demo the compression query and the resultant dataset manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>count</th>\n",
       "      <th>sum_Y</th>\n",
       "      <th>sum_Y_sq</th>\n",
       "      <th>mean_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12661</td>\n",
       "      <td>392740.854101</td>\n",
       "      <td>1.219542e+07</td>\n",
       "      <td>31.019734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12555</td>\n",
       "      <td>338879.628202</td>\n",
       "      <td>9.159219e+06</td>\n",
       "      <td>26.991607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12541</td>\n",
       "      <td>301167.857805</td>\n",
       "      <td>7.244984e+06</td>\n",
       "      <td>24.014661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12749</td>\n",
       "      <td>229340.530330</td>\n",
       "      <td>4.138291e+06</td>\n",
       "      <td>17.988903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12409</td>\n",
       "      <td>384742.457149</td>\n",
       "      <td>1.194167e+07</td>\n",
       "      <td>31.005114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     D    f1    f2  count          sum_Y      sum_Y_sq     mean_Y\n",
       "0  1.0  12.0   9.0  12661  392740.854101  1.219542e+07  31.019734\n",
       "1  1.0   2.0  12.0  12555  338879.628202  9.159219e+06  26.991607\n",
       "2  1.0  13.0   5.0  12541  301167.857805  7.244984e+06  24.014661\n",
       "3  1.0  17.0   0.0  12749  229340.530330  4.138291e+06  17.988903\n",
       "4  1.0  18.0   6.0  12409  384742.457149  1.194167e+07  31.005114"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_name = \"large_dataset.db\"\n",
    "conn = duckdb.connect(db_name)\n",
    "q = \"\"\"\n",
    "        SELECT D, f1, f2, COUNT(*) as count,\n",
    "        SUM(Y) as sum_Y,\n",
    "        SUM(POW(Y, 2)) as sum_Y_sq,\n",
    "        FROM data\n",
    "        GROUP BY D, f1, f2\n",
    "\"\"\"\n",
    "compressed_df = conn.execute(q).fetchdf()\n",
    "conn.close()\n",
    "\n",
    "compressed_df.eval(\"mean_Y = sum_Y / count\", inplace=True)\n",
    "print(compressed_df.shape)\n",
    "compressed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've reduced a 1 million observation dataset to 800 observations. This will speed up estimation dramatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "\n",
    "$$\n",
    "Y_i + X_i \\beta + \\alpha_i + \\epsilon_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### analytic HC1 standard errors\n",
    "\n",
    "The easiest case is linear regression with robust SEs, which can be computed directly from compressed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 504 ms, sys: 33.9 ms, total: 537 ms\n",
      "Wall time: 88.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alal/Desktop/code/duckreg/duckreg/estimators.py:130: RuntimeWarning: divide by zero encountered in matmul\n",
      "  yhat = (X @ betahat).reshape(-1, 1)\n",
      "/Users/alal/Desktop/code/duckreg/duckreg/estimators.py:130: RuntimeWarning: overflow encountered in matmul\n",
      "  yhat = (X @ betahat).reshape(-1, 1)\n",
      "/Users/alal/Desktop/code/duckreg/duckreg/estimators.py:130: RuntimeWarning: invalid value encountered in matmul\n",
      "  yhat = (X @ betahat).reshape(-1, 1)\n",
      "/Users/alal/Desktop/code/duckreg/duckreg/estimators.py:132: RuntimeWarning: divide by zero encountered in matmul\n",
      "  bread = np.linalg.inv(X.T @ np.diag(n.flatten()) @ X)\n",
      "/Users/alal/Desktop/code/duckreg/duckreg/estimators.py:132: RuntimeWarning: overflow encountered in matmul\n",
      "  bread = np.linalg.inv(X.T @ np.diag(n.flatten()) @ X)\n",
      "/Users/alal/Desktop/code/duckreg/duckreg/estimators.py:132: RuntimeWarning: invalid value encountered in matmul\n",
      "  bread = np.linalg.inv(X.T @ np.diag(n.flatten()) @ X)\n",
      "/Users/alal/Desktop/code/duckreg/duckreg/estimators.py:133: RuntimeWarning: divide by zero encountered in matmul\n",
      "  meat = X.T @ np.diag(rss_g.flatten()) @ X\n",
      "/Users/alal/Desktop/code/duckreg/duckreg/estimators.py:133: RuntimeWarning: overflow encountered in matmul\n",
      "  meat = X.T @ np.diag(rss_g.flatten()) @ X\n",
      "/Users/alal/Desktop/code/duckreg/duckreg/estimators.py:133: RuntimeWarning: invalid value encountered in matmul\n",
      "  meat = X.T @ np.diag(rss_g.flatten()) @ X\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000274</td>\n",
       "      <td>0.000862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.000632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000035</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.000067</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_estimate  standard_error\n",
       "0       -0.000274        0.000862\n",
       "1        0.999347        0.000632\n",
       "2        1.000035        0.000055\n",
       "3        2.000067        0.000055"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "m = DuckRegression(\n",
    "    db_name=\"large_dataset.db\",\n",
    "    table_name=\"data\",\n",
    "    formula=\"Y ~ D + f1 + f2\",\n",
    "    cluster_col=\"\",\n",
    "    n_bootstraps=0,\n",
    "    seed=42,\n",
    ")\n",
    "m.fit()\n",
    "m.fit_vcov()\n",
    "results = m.summary()\n",
    "restab = pd.DataFrame(\n",
    "    np.c_[results[\"point_estimate\"], results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the fully disaggregated data implementation (with fixed effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alal/Desktop/code/duckreg/.venv/lib/python3.12/site-packages/pyfixest/estimation/feols_.py:2679: RuntimeWarning: divide by zero encountered in matmul\n",
      "  tXX = X.T @ X\n",
      "/Users/alal/Desktop/code/duckreg/.venv/lib/python3.12/site-packages/pyfixest/estimation/feols_.py:2679: RuntimeWarning: overflow encountered in matmul\n",
      "  tXX = X.T @ X\n",
      "/Users/alal/Desktop/code/duckreg/.venv/lib/python3.12/site-packages/pyfixest/estimation/feols_.py:2679: RuntimeWarning: invalid value encountered in matmul\n",
      "  tXX = X.T @ X\n",
      "/Users/alal/Desktop/code/duckreg/.venv/lib/python3.12/site-packages/pyfixest/estimation/feols_.py:552: RuntimeWarning: divide by zero encountered in matmul\n",
      "  self._tZX = _Z.T @ _X\n",
      "/Users/alal/Desktop/code/duckreg/.venv/lib/python3.12/site-packages/pyfixest/estimation/feols_.py:552: RuntimeWarning: overflow encountered in matmul\n",
      "  self._tZX = _Z.T @ _X\n",
      "/Users/alal/Desktop/code/duckreg/.venv/lib/python3.12/site-packages/pyfixest/estimation/feols_.py:552: RuntimeWarning: invalid value encountered in matmul\n",
      "  self._tZX = _Z.T @ _X\n",
      "/Users/alal/Desktop/code/duckreg/.venv/lib/python3.12/site-packages/pyfixest/estimation/feols_.py:553: RuntimeWarning: divide by zero encountered in matmul\n",
      "  self._tZy = _Z.T @ _Y\n",
      "/Users/alal/Desktop/code/duckreg/.venv/lib/python3.12/site-packages/pyfixest/estimation/feols_.py:553: RuntimeWarning: overflow encountered in matmul\n",
      "  self._tZy = _Z.T @ _Y\n",
      "/Users/alal/Desktop/code/duckreg/.venv/lib/python3.12/site-packages/pyfixest/estimation/feols_.py:553: RuntimeWarning: invalid value encountered in matmul\n",
      "  self._tZy = _Z.T @ _Y\n",
      "/Users/alal/Desktop/code/duckreg/.venv/lib/python3.12/site-packages/pyfixest/estimation/feols_.py:820: RuntimeWarning: divide by zero encountered in matmul\n",
      "  Omega = transformed_scores.T @ transformed_scores\n",
      "/Users/alal/Desktop/code/duckreg/.venv/lib/python3.12/site-packages/pyfixest/estimation/feols_.py:820: RuntimeWarning: overflow encountered in matmul\n",
      "  Omega = transformed_scores.T @ transformed_scores\n",
      "/Users/alal/Desktop/code/duckreg/.venv/lib/python3.12/site-packages/pyfixest/estimation/feols_.py:820: RuntimeWarning: invalid value encountered in matmul\n",
      "  Omega = transformed_scores.T @ transformed_scores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.83 s, sys: 395 ms, total: 2.23 s\n",
      "Wall time: 2.36 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Std. Error</th>\n",
       "      <th>t value</th>\n",
       "      <th>Pr(&gt;|t|)</th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coefficient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>1580.194126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998107</td>\n",
       "      <td>1.000586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Estimate  Std. Error      t value  Pr(>|t|)      2.5%     97.5%\n",
       "Coefficient                                                                 \n",
       "D            0.999347    0.000632  1580.194126       0.0  0.998107  1.000586"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "m_pf = pf.feols(\"Y ~ D | f1 + f2\", df, vcov=\"hetero\")\n",
    "m_pf.tidy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyfixest with full data takes ~ 40x longer to compute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.1 s, sys: 5.67 s, total: 53.8 s\n",
      "Wall time: 36.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.9993468884181829), np.float64(0.000632420328603603))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "m_smf = smf.ols(\"Y ~ D + C(f1) + C(f2)\", df).fit(cov_type=\"HC1\")\n",
    "m_smf.params.loc[\"D\"], m_smf.bse.loc[\"D\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "speedup factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(407.90960451977406, 26.666666666666668)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "36.1 / 0.0885, 2.36 / 0.0885"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full data run in statsmodels takes around 600x longer than the compressed representation in `DuckRegression`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duckreg</th>\n",
       "      <th>pyfixest</th>\n",
       "      <th>statsmodels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>estimate</th>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.999347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std.error</th>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            duckreg  pyfixest  statsmodels\n",
       "estimate   0.999347  0.999347     0.999347\n",
       "std.error  0.000632  0.000632     0.000632"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    np.c_[\n",
    "        np.r_[results[\"point_estimate\"][1], results[\"standard_error\"][1]],\n",
    "        m_pf.tidy().iloc[0][[\"Estimate\", \"Std. Error\"]].values,\n",
    "        np.r_[m_smf.params.loc[\"D\"], m_smf.bse.loc[\"D\"]],\n",
    "    ],\n",
    "    columns=[\"duckreg\", \"pyfixest\", \"statsmodels\"],\n",
    "    index=[\"estimate\", \"std.error\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cluster-robust standard errors\n",
    "\n",
    "for clustered data, we will use the cluster bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 21.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000274</td>\n",
       "      <td>0.000569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000035</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.000067</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_estimate  standard_error\n",
       "0       -0.000274        0.000569\n",
       "1        0.999347        0.000736\n",
       "2        1.000035        0.000039\n",
       "3        2.000067        0.000037"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = DuckRegression(\n",
    "    db_name=\"large_dataset.db\",\n",
    "    table_name=\"data\",\n",
    "    formula=\"Y ~ D + f1 + f2\",\n",
    "    cluster_col=\"f1\",\n",
    "    n_bootstraps=100,\n",
    "    seed=42,\n",
    ")\n",
    "m.fit()\n",
    "results = m.summary()\n",
    "\n",
    "restab = pd.DataFrame(\n",
    "    np.c_[results[\"point_estimate\"], results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underlying estimator is powered by the following queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        SELECT D, f1, f2, COUNT(*) as count, SUM(Y) as sum_Y, SUM(POW(Y, 2)) as sum_Y_sq\n",
      "        FROM data\n",
      "        GROUP BY D, f1, f2\n",
      "        \n",
      "\n",
      "            SELECT D, f1, f2, COUNT(*) as count, SUM(Y) as sum_Y\n",
      "            FROM data\n",
      "            WHERE f1 IN (SELECT unnest((?)))\n",
      "            GROUP BY D, f1, f2\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(m.agg_query)\n",
    "print(m.bootstrap_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run regressions on multiple outcome variables painlessly since we only need to keep track of summary stats; just include all dependent variables on the RHS of the formula. The output of `DuckRegression.fit()` concatenates the results of all regressions into a single table, which can then be sliced to extract the relevant coefficients and SEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 19.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'point_estimate': array([-2.73682294e-04, -4.39868205e-04,  9.99347122e-01, -9.99443294e-01,\n",
      "        1.00003536e+00,  1.00006450e+00,  2.00006685e+00,  1.99995671e+00]), 'standard_error': array([6.70325435e-04, 4.15857348e-04, 7.26599979e-04, 4.45407815e-04,\n",
      "       4.67005434e-05, 4.95007891e-05, 3.96508809e-05, 3.66987192e-05])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m2 = DuckRegression(\n",
    "    db_name=\"large_dataset.db\",\n",
    "    table_name=\"data\",\n",
    "    formula=\"Y + Y2 ~ D + f1 + f2\",\n",
    "    cluster_col=\"f1\",\n",
    "    n_bootstraps=100,\n",
    "    seed=232,\n",
    ")\n",
    "\n",
    "m2.fit()\n",
    "print(results := m2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compressed data contains summary stats on all outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>count</th>\n",
       "      <th>sum_Y</th>\n",
       "      <th>sum_Y2</th>\n",
       "      <th>sum_Y_sq</th>\n",
       "      <th>sum_Y2_sq</th>\n",
       "      <th>mean_Y</th>\n",
       "      <th>mean_Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12511</td>\n",
       "      <td>500242.125603</td>\n",
       "      <td>500408.983974</td>\n",
       "      <td>2.001441e+07</td>\n",
       "      <td>2.002760e+07</td>\n",
       "      <td>39.984184</td>\n",
       "      <td>39.997521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12533</td>\n",
       "      <td>451037.942006</td>\n",
       "      <td>451074.040468</td>\n",
       "      <td>1.624431e+07</td>\n",
       "      <td>1.624701e+07</td>\n",
       "      <td>35.988027</td>\n",
       "      <td>35.990907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12514</td>\n",
       "      <td>262840.745544</td>\n",
       "      <td>262799.047622</td>\n",
       "      <td>5.533116e+06</td>\n",
       "      <td>5.531278e+06</td>\n",
       "      <td>21.003735</td>\n",
       "      <td>21.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12530</td>\n",
       "      <td>526334.167747</td>\n",
       "      <td>501171.280714</td>\n",
       "      <td>2.212209e+07</td>\n",
       "      <td>2.005817e+07</td>\n",
       "      <td>42.005919</td>\n",
       "      <td>39.997708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12727</td>\n",
       "      <td>216544.840414</td>\n",
       "      <td>190925.760161</td>\n",
       "      <td>3.697190e+06</td>\n",
       "      <td>2.876925e+06</td>\n",
       "      <td>17.014602</td>\n",
       "      <td>15.001631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12474</td>\n",
       "      <td>299411.228483</td>\n",
       "      <td>274355.008636</td>\n",
       "      <td>7.199418e+06</td>\n",
       "      <td>6.046702e+06</td>\n",
       "      <td>24.002824</td>\n",
       "      <td>21.994149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12532</td>\n",
       "      <td>162873.522865</td>\n",
       "      <td>137663.988075</td>\n",
       "      <td>2.129424e+06</td>\n",
       "      <td>1.524742e+06</td>\n",
       "      <td>12.996611</td>\n",
       "      <td>10.984997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12358</td>\n",
       "      <td>173189.061847</td>\n",
       "      <td>148405.392402</td>\n",
       "      <td>2.439499e+06</td>\n",
       "      <td>1.794483e+06</td>\n",
       "      <td>14.014328</td>\n",
       "      <td>12.008852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12535</td>\n",
       "      <td>526500.728827</td>\n",
       "      <td>501413.405866</td>\n",
       "      <td>2.212681e+07</td>\n",
       "      <td>2.006959e+07</td>\n",
       "      <td>42.002451</td>\n",
       "      <td>40.001069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12425</td>\n",
       "      <td>322989.182889</td>\n",
       "      <td>322877.826921</td>\n",
       "      <td>8.408477e+06</td>\n",
       "      <td>8.402737e+06</td>\n",
       "      <td>25.995105</td>\n",
       "      <td>25.986143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       D    f1    f2  count          sum_Y         sum_Y2      sum_Y_sq  \\\n",
       "0    0.0   6.0  17.0  12511  500242.125603  500408.983974  2.001441e+07   \n",
       "1    0.0  14.0  11.0  12533  451037.942006  451074.040468  1.624431e+07   \n",
       "2    0.0  13.0   4.0  12514  262840.745544  262799.047622  5.533116e+06   \n",
       "3    1.0   9.0  16.0  12530  526334.167747  501171.280714  2.212209e+07   \n",
       "4    1.0  12.0   2.0  12727  216544.840414  190925.760161  3.697190e+06   \n",
       "..   ...   ...   ...    ...            ...            ...           ...   \n",
       "795  1.0   3.0  10.0  12474  299411.228483  274355.008636  7.199418e+06   \n",
       "796  1.0  10.0   1.0  12532  162873.522865  137663.988075  2.129424e+06   \n",
       "797  1.0  13.0   0.0  12358  173189.061847  148405.392402  2.439499e+06   \n",
       "798  1.0  17.0  12.0  12535  526500.728827  501413.405866  2.212681e+07   \n",
       "799  0.0   8.0   9.0  12425  322989.182889  322877.826921  8.408477e+06   \n",
       "\n",
       "        sum_Y2_sq     mean_Y    mean_Y2  \n",
       "0    2.002760e+07  39.984184  39.997521  \n",
       "1    1.624701e+07  35.988027  35.990907  \n",
       "2    5.531278e+06  21.003735  21.000403  \n",
       "3    2.005817e+07  42.005919  39.997708  \n",
       "4    2.876925e+06  17.014602  15.001631  \n",
       "..            ...        ...        ...  \n",
       "795  6.046702e+06  24.002824  21.994149  \n",
       "796  1.524742e+06  12.996611  10.984997  \n",
       "797  1.794483e+06  14.014328  12.008852  \n",
       "798  2.006959e+07  42.002451  40.001069  \n",
       "799  8.402737e+06  25.995105  25.986143  \n",
       "\n",
       "[800 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.df_compressed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output needs some post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept_Y</th>\n",
       "      <td>-0.000274</td>\n",
       "      <td>0.000670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intercept_Y2</th>\n",
       "      <td>-0.000440</td>\n",
       "      <td>0.000416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_Y</th>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.000727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_Y2</th>\n",
       "      <td>-0.999443</td>\n",
       "      <td>0.000445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_Y</th>\n",
       "      <td>1.000035</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_Y2</th>\n",
       "      <td>1.000064</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2_Y</th>\n",
       "      <td>2.000067</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2_Y2</th>\n",
       "      <td>1.999957</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              point_estimate  standard_error\n",
       "Intercept_Y        -0.000274        0.000670\n",
       "Intercept_Y2       -0.000440        0.000416\n",
       "D_Y                 0.999347        0.000727\n",
       "D_Y2               -0.999443        0.000445\n",
       "f1_Y                1.000035        0.000047\n",
       "f1_Y2               1.000064        0.000050\n",
       "f2_Y                2.000067        0.000040\n",
       "f2_Y2               1.999957        0.000037"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restab = pd.DataFrame(\n",
    "    np.c_[results[\"point_estimate\"], results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    "    index=[f\"{x}_{y}\" for x in [\"Intercept\", \"D\", \"f1\", \"f2\"] for y in [\"Y\", \"Y2\"]],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panel Data\n",
    "\n",
    "We have specialised estimators for panel data with N >> T, where the conventional compressed approach is inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_panel(\n",
    "    # Parameters\n",
    "    N=1_000_000,\n",
    "    T=35,  # Number of units and time periods\n",
    "    T0=5,  # Treatment starts at T0\n",
    "    tau=0.005,\n",
    "    sigma_list=[5, 2, 0.01, 2],\n",
    "    seed=42,\n",
    "):\n",
    "    np.random.seed(seed)\n",
    "    sigma_unit, sigma_time, sigma_tt, sigma_e = sigma_list\n",
    "    # Generate data\n",
    "    unit_ids = np.repeat(np.arange(N), T)\n",
    "    time_ids = np.tile(np.arange(T), N)\n",
    "\n",
    "    # Generate unit-specific intercepts and time trends\n",
    "    unit_fe = np.random.normal(0, sigma_unit, N)\n",
    "    time_fe = np.random.normal(\n",
    "        0, sigma_time, T\n",
    "    )  # Common shocks for all units at each time period\n",
    "    unit_tt = np.random.normal(0, sigma_tt, N)\n",
    "\n",
    "    # Generate treatment indicator (randomly assigned)\n",
    "    W = np.random.binomial(1, 0.5, N)\n",
    "    W = np.repeat(W, T)\n",
    "    W = W * (time_ids >= T0)\n",
    "\n",
    "    rho = 0.7  # Autoregressive parameter for residuals\n",
    "    # Generate serially correlated residuals for each unit (optimized version)\n",
    "    residuals = np.zeros((N, T))\n",
    "    residuals[:, 0] = np.random.normal(0, sigma_e, N)\n",
    "    epsilon = np.random.normal(0, 1, (N, T - 1))\n",
    "    factor = 0.5 * np.sqrt(1 - rho**2)\n",
    "    for t in range(1, T):\n",
    "        residuals[:, t] = rho * residuals[:, t - 1] + factor * epsilon[:, t - 1]\n",
    "    # iid\n",
    "    # residuals = np.random.normal(0, 0.5, N*T)\n",
    "\n",
    "    # Generate outcome\n",
    "    Y = (\n",
    "        np.repeat(unit_fe, T)\n",
    "        + np.repeat(unit_tt, T) * time_ids\n",
    "        + tau * W  # Treatment effect is 1\n",
    "        + np.tile(time_fe, N)  # time FE\n",
    "        + residuals.flatten()\n",
    "    )  # Individual noise\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\"unit\": unit_ids, \"time\": time_ids, \"Y\": Y, \"W\": W})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = sim_panel(tau=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name, table_name = \"panel_data.db\", \"panel_data\"\n",
    "# write to database\n",
    "conn = duckdb.connect(db_name)\n",
    "conn.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "conn.execute(f\"CREATE TABLE {table_name} AS SELECT * from df\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peek at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unit  time         Y  W\n",
      "0     0     0  3.096240  0\n",
      "1     0     1  2.656935  0\n",
      "2     0     2  5.084101  0\n",
      "3     0     3  3.274999  0\n",
      "4     0     4  4.638763  0\n"
     ]
    }
   ],
   "source": [
    "conn = duckdb.connect(db_name)\n",
    "print(conn.execute(\"SELECT * FROM panel_data LIMIT 5\").fetchdf())\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckreg.estimators import DuckMundlak, DuckDoubleDemeaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mundlak\n",
    "\n",
    "\n",
    "One-way mundlak \n",
    "\n",
    "$$\n",
    "Y_{it} = \\alpha + \\beta X_{it} + \\gamma \\bar{X}_{i} + \\epsilon_{it}\n",
    "$$\n",
    "\n",
    "Two-way mundlak\n",
    "\n",
    "$$\n",
    "Y_{it} = \\alpha + \\beta X_{it} + \\gamma \\bar{X}_{i, \\cdot} + \\delta \\bar{X}_{\\cdot, t} + \\epsilon_{it}\n",
    "$$\n",
    "\n",
    "both of which can be compressed easily with `duckdb`.\n",
    "\n",
    "These representations are much more efficient than the above general procedure because the unit and time fixed effects are typically very high dimensional, but covariate averages are not. Also see [Arkhangelsky and Imbens](https://arxiv.org/abs/1807.02099) on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:24<00:00,  2.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.896134</td>\n",
       "      <td>0.005633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.003877</td>\n",
       "      <td>0.001765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009106</td>\n",
       "      <td>0.009642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.413955</td>\n",
       "      <td>0.002209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_estimate  standard_error\n",
       "0        0.896134        0.005633\n",
       "1        1.003877        0.001765\n",
       "2        0.009106        0.009642\n",
       "3       -2.413955        0.002209"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mundlak = DuckMundlak(\n",
    "    db_name=\"panel_data.db\",\n",
    "    table_name=\"panel_data\",\n",
    "    outcome_var=\"Y\",\n",
    "    covariates=[\"W\"],\n",
    "    unit_col=\"unit\",\n",
    "    time_col=\"time\",\n",
    "    cluster_col=\"unit\",\n",
    "    n_bootstraps=50,\n",
    "    seed=929,\n",
    ")\n",
    "mundlak.fit()\n",
    "\n",
    "mundlak_results = mundlak.summary()\n",
    "\n",
    "restab = pd.DataFrame(\n",
    "    np.c_[mundlak_results[\"point_estimate\"], mundlak_results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powered by the following sequence of queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        CREATE TEMP TABLE unit_avgs AS\n",
      "        SELECT unit,\n",
      "               AVG(W) AS avg_W_unit\n",
      "        FROM panel_data\n",
      "        GROUP BY unit\n",
      "        \n",
      "\n",
      "            CREATE TEMP TABLE time_avgs AS\n",
      "            SELECT time,\n",
      "                   AVG(W) AS avg_W_time\n",
      "            FROM panel_data\n",
      "            GROUP BY time\n",
      "            \n",
      "\n",
      "        CREATE TEMP TABLE design_matrix AS\n",
      "        SELECT\n",
      "            t.unit,\n",
      "            t.time,\n",
      "            t.Y,\n",
      "            t.W,\n",
      "            u.avg_W_unit\n",
      "            , tm.avg_W_time\n",
      "        FROM panel_data t\n",
      "        JOIN unit_avgs u ON t.unit = u.unit\n",
      "        JOIN time_avgs tm ON t.time = tm.time\n",
      "        \n",
      "\n",
      "        SELECT\n",
      "            W, avg_W_unit, avg_W_time,\n",
      "            COUNT(*) as count,\n",
      "            SUM(Y) as sum_Y\n",
      "        FROM design_matrix\n",
      "        GROUP BY W, avg_W_unit, avg_W_time\n",
      "        \n",
      "\n",
      "            SELECT\n",
      "                W,\n",
      "                avg_W_unit\n",
      "                , avg_W_time,\n",
      "                COUNT(*) as count,\n",
      "                SUM(Y) as sum_Y\n",
      "            FROM design_matrix\n",
      "            WHERE unit IN (SELECT unnest((?)))\n",
      "            GROUP BY W,\n",
      "                        avg_W_unit\n",
      "                        , avg_W_time\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(mundlak.unit_avg_query)\n",
    "print(mundlak.time_avg_query)\n",
    "print(mundlak.design_matrix_query)\n",
    "print(mundlak.compress_query)\n",
    "print(mundlak.bootstrap_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Demeaning\n",
    "\n",
    "$$\n",
    "Y_{it} = \\alpha + \\ddot{X}_{it} \\beta + \\epsilon_{it}\n",
    "$$\n",
    "\n",
    "where $\\ddot{X}_{it} = X_{it} - \\bar{X}_{i, \\cdot} - \\bar{X}_{\\cdot, t} + \\bar{X}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:47<00:00,  2.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.295524</td>\n",
       "      <td>0.003857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.003877</td>\n",
       "      <td>0.002097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_estimate  standard_error\n",
       "0        0.295524        0.003857\n",
       "1        1.003877        0.002097"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_demean = DuckDoubleDemeaning(\n",
    "    db_name=\"panel_data.db\",\n",
    "    table_name=\"panel_data\",\n",
    "    outcome_var=\"Y\",\n",
    "    treatment_var=\"W\",\n",
    "    unit_col=\"unit\",\n",
    "    time_col=\"time\",\n",
    "    cluster_col=\"unit\",\n",
    "    n_bootstraps=100,\n",
    "    seed=828,\n",
    ")\n",
    "\n",
    "double_demean.fit()\n",
    "\n",
    "dd_results = double_demean.summary()\n",
    "\n",
    "restab = pd.DataFrame(\n",
    "    np.c_[dd_results[\"point_estimate\"], dd_results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        CREATE TEMP TABLE overall_mean AS\n",
      "        SELECT AVG(W) AS mean_W\n",
      "        FROM panel_data\n",
      "        \n",
      "\n",
      "        CREATE TEMP TABLE unit_means AS\n",
      "        SELECT unit, AVG(W) AS mean_W_unit\n",
      "        FROM panel_data\n",
      "        GROUP BY unit\n",
      "        \n",
      "\n",
      "        CREATE TEMP TABLE time_means AS\n",
      "        SELECT time, AVG(W) AS mean_W_time\n",
      "        FROM panel_data\n",
      "        GROUP BY time\n",
      "        \n",
      "\n",
      "        CREATE TEMP TABLE double_demeaned AS\n",
      "        SELECT\n",
      "            t.unit,\n",
      "            t.time,\n",
      "            t.Y,\n",
      "            t.W - um.mean_W_unit - tm.mean_W_time + om.mean_W AS ddot_W\n",
      "        FROM panel_data t\n",
      "        JOIN unit_means um ON t.unit = um.unit\n",
      "        JOIN time_means tm ON t.time = tm.time\n",
      "        CROSS JOIN overall_mean om\n",
      "        \n",
      "\n",
      "        SELECT\n",
      "            ddot_W,\n",
      "            COUNT(*) as count,\n",
      "            SUM(Y) as sum_Y\n",
      "        FROM double_demeaned\n",
      "        GROUP BY ddot_W\n",
      "        \n",
      "\n",
      "            SELECT\n",
      "                ddot_W,\n",
      "                COUNT(*) as count,\n",
      "                SUM(Y) as sum_Y\n",
      "            FROM double_demeaned\n",
      "            WHERE unit IN (SELECT unnest((?)))\n",
      "            GROUP BY ddot_W\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(double_demean.overall_mean_query)\n",
    "print(double_demean.unit_mean_query)\n",
    "print(double_demean.time_mean_query)\n",
    "print(double_demean.double_demean_query)\n",
    "print(double_demean.compress_query)\n",
    "print(double_demean.bootstrap_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
