{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `duckreg`: Out-of-memory regressions with `duckdb`\n",
    "\n",
    "Remember to carefully examine the underlying queries that generate the data; the package merely passes it into `np.linalg.lstsq` to solve the least squares problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from duckreg.estimators import DuckRegression\n",
    "import duckdb\n",
    "import pyfixest as pf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with discrete covariates\n",
    "\n",
    "The largest gains from compression arise when the right hand side variables are discrete, which is also the setting where linearity is an innocuous assumption (especially when the RHS is saturated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "def generate_sample_data(N=10_000_000, seed=12345):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    D = rng.choice([0, 1], size=(N, 1))\n",
    "    X = rng.choice(range(20), (N, 2), True)\n",
    "    Y = D + X @ np.array([1, 2]).reshape(2, 1) + rng.normal(size=(N, 1))\n",
    "    Y2 = -1 * D + X @ np.array([1, 2]).reshape(2, 1) + rng.normal(size=(N, 1))\n",
    "    df = pd.DataFrame(\n",
    "        np.concatenate([Y, Y2, D, X], axis=1), columns=[\"Y\", \"Y2\", \"D\", \"f1\", \"f2\"]\n",
    "    ).assign(rowid=range(N))\n",
    "    return df\n",
    "\n",
    "\n",
    "# Function to create and populate DuckDB database\n",
    "def create_duckdb_database(df, db_name=\"large_dataset.db\", table=\"data\"):\n",
    "    conn = duckdb.connect(db_name)\n",
    "    conn.execute(f\"DROP TABLE IF EXISTS {table}\")\n",
    "    conn.execute(f\"CREATE TABLE {table} AS SELECT * FROM df\")\n",
    "    conn.close()\n",
    "    print(f\"Data loaded into DuckDB database: {db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into DuckDB database: large_dataset.db\n"
     ]
    }
   ],
   "source": [
    "# Generate and save data\n",
    "df = generate_sample_data()\n",
    "db_name = \"large_dataset.db\"\n",
    "create_duckdb_database(df, db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the dataset. This dataset could be unreasonably large, which prevents the use of conventional in-memory regression techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>Y2</th>\n",
       "      <th>D</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>rowid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.226866</td>\n",
       "      <td>24.444717</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.088713</td>\n",
       "      <td>35.392007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.472292</td>\n",
       "      <td>21.185366</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.842856</td>\n",
       "      <td>38.012720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.136978</td>\n",
       "      <td>22.168634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Y         Y2    D    f1    f2  rowid\n",
       "0  27.226866  24.444717  1.0  16.0   5.0      0\n",
       "1  35.088713  35.392007  0.0   1.0  17.0      1\n",
       "2  22.472292  21.185366  1.0   6.0   8.0      2\n",
       "3  39.842856  38.012720  0.0   9.0  15.0      3\n",
       "4  23.136978  22.168634  0.0  10.0   6.0      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_name = \"large_dataset.db\"\n",
    "conn = duckdb.connect(db_name)\n",
    "query = \"SELECT * FROM data limit 5\"\n",
    "conn.execute(query).fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core idea of compressed representations is to retain the minimal set of sufficient statistics to compute the point estimate and variance-covariance matrix. We first demo the compression query and the resultant dataset manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>count</th>\n",
       "      <th>sum_Y</th>\n",
       "      <th>sum_Y_sq</th>\n",
       "      <th>mean_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12527</td>\n",
       "      <td>413485.030949</td>\n",
       "      <td>1.366067e+07</td>\n",
       "      <td>33.007506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12289</td>\n",
       "      <td>380839.544911</td>\n",
       "      <td>1.181442e+07</td>\n",
       "      <td>30.990280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12518</td>\n",
       "      <td>375456.350549</td>\n",
       "      <td>1.127372e+07</td>\n",
       "      <td>29.993318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12642</td>\n",
       "      <td>214930.812301</td>\n",
       "      <td>3.666901e+06</td>\n",
       "      <td>17.001330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12615</td>\n",
       "      <td>365865.474043</td>\n",
       "      <td>1.062339e+07</td>\n",
       "      <td>29.002416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     D    f1    f2  count          sum_Y      sum_Y_sq     mean_Y\n",
       "0  1.0   6.0  13.0  12527  413485.030949  1.366067e+07  33.007506\n",
       "1  0.0   1.0  15.0  12289  380839.544911  1.181442e+07  30.990280\n",
       "2  1.0   1.0  14.0  12518  375456.350549  1.127372e+07  29.993318\n",
       "3  0.0   3.0   7.0  12642  214930.812301  3.666901e+06  17.001330\n",
       "4  1.0  14.0   7.0  12615  365865.474043  1.062339e+07  29.002416"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_name = \"large_dataset.db\"\n",
    "conn = duckdb.connect(db_name)\n",
    "q = \"\"\"\n",
    "        SELECT D, f1, f2, COUNT(*) as count,\n",
    "        SUM(Y) as sum_Y,\n",
    "        SUM(POW(Y, 2)) as sum_Y_sq,\n",
    "        FROM data\n",
    "        GROUP BY D, f1, f2\n",
    "\"\"\"\n",
    "compressed_df = conn.execute(q).fetchdf()\n",
    "conn.close()\n",
    "\n",
    "compressed_df.eval(\"mean_Y = sum_Y / count\", inplace=True)\n",
    "print(compressed_df.shape)\n",
    "compressed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've reduced a 1 million observation dataset to 800 observations. This will speed up estimation dramatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "\n",
    "$$\n",
    "Y_i + X_i \\beta + \\alpha_i + \\epsilon_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### analytic HC1 standard errors\n",
    "\n",
    "The easiest case is linear regression with robust SEs, which can be computed directly from compressed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.79 s, sys: 72.9 ms, total: 1.86 s\n",
      "Wall time: 372 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000274</td>\n",
       "      <td>0.000862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.000632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000035</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.000067</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_estimate  standard_error\n",
       "0       -0.000274        0.000862\n",
       "1        0.999347        0.000632\n",
       "2        1.000035        0.000055\n",
       "3        2.000067        0.000055"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "m = DuckRegression(\n",
    "    db_name=\"large_dataset.db\",\n",
    "    table_name=\"data\",\n",
    "    formula=\"Y ~ D + f1 + f2\",\n",
    "    cluster_col=\"\",\n",
    "    n_bootstraps=0,\n",
    "    seed=42,\n",
    ")\n",
    "m.fit()\n",
    "m.fit_vcov()\n",
    "results = m.summary()\n",
    "restab = pd.DataFrame(\n",
    "    np.c_[results[\"point_estimate\"], results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the fully disaggregated data implementation (with fixed effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.07 s, sys: 553 ms, total: 9.63 s\n",
      "Wall time: 6.18 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Std. Error</th>\n",
       "      <th>t value</th>\n",
       "      <th>Pr(&gt;|t|)</th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coefficient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>1580.194126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998107</td>\n",
       "      <td>1.000586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Estimate  Std. Error      t value  Pr(>|t|)      2.5%     97.5%\n",
       "Coefficient                                                                 \n",
       "D            0.999347    0.000632  1580.194126       0.0  0.998107  1.000586"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "m_pf = pf.feols(\"Y ~ D | f1 + f2\", df, vcov=\"hetero\")\n",
    "m_pf.tidy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyfixest with full data takes ~ 40x longer to compute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 58s, sys: 39.8 s, total: 5min 38s\n",
      "Wall time: 2min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.999346888418407), np.float64(0.0006324203286037654))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "m_smf = smf.ols(\"Y ~ D + C(f1) + C(f2)\", df).fit(cov_type=\"HC1\")\n",
    "m_smf.params.loc[\"D\"], m_smf.bse.loc[\"D\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full data run in statsmodels takes around 600x longer than the compressed representation in `DuckRegression`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duckreg</th>\n",
       "      <th>pyfixest</th>\n",
       "      <th>statsmodels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>estimate</th>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.999347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std.error</th>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            duckreg  pyfixest  statsmodels\n",
       "estimate   0.999347  0.999347     0.999347\n",
       "std.error  0.000632  0.000632     0.000632"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    np.c_[\n",
    "        np.r_[results[\"point_estimate\"][1], results[\"standard_error\"][1]],\n",
    "        m_pf.tidy().iloc[0][[\"Estimate\", \"Std. Error\"]].values,\n",
    "        np.r_[m_smf.params.loc[\"D\"], m_smf.bse.loc[\"D\"]],\n",
    "    ],\n",
    "    columns=[\"duckreg\", \"pyfixest\", \"statsmodels\"],\n",
    "    index=[\"estimate\", \"std.error\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cluster-robust standard errors\n",
    "\n",
    "for clustered data, we will use the cluster bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:33<00:00,  2.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000274</td>\n",
       "      <td>0.000569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000035</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.000067</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_estimate  standard_error\n",
       "0       -0.000274        0.000569\n",
       "1        0.999347        0.000736\n",
       "2        1.000035        0.000039\n",
       "3        2.000067        0.000037"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = DuckRegression(\n",
    "    db_name=\"large_dataset.db\",\n",
    "    table_name=\"data\",\n",
    "    formula=\"Y ~ D + f1 + f2\",\n",
    "    cluster_col=\"f1\",\n",
    "    n_bootstraps=100,\n",
    "    seed=42,\n",
    ")\n",
    "m.fit()\n",
    "results = m.summary()\n",
    "\n",
    "restab = pd.DataFrame(\n",
    "    np.c_[results[\"point_estimate\"], results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underlying estimator is powered by the following queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        SELECT D, f1, f2, COUNT(*) as count, SUM(Y) as sum_Y, SUM(POW(Y, 2)) as sum_Y_sq\n",
      "        FROM data\n",
      "        GROUP BY D, f1, f2\n",
      "        \n",
      "\n",
      "            SELECT D, f1, f2, COUNT(*) as count, SUM(Y) as sum_Y\n",
      "            FROM data\n",
      "            WHERE f1 IN (SELECT unnest((?)))\n",
      "            GROUP BY D, f1, f2\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(m.agg_query)\n",
    "print(m.bootstrap_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run regressions on multiple outcome variables painlessly since we only need to keep track of summary stats; just include all dependent variables on the RHS of the formula. The output of `DuckRegression.fit()` concatenates the results of all regressions into a single table, which can then be sliced to extract the relevant coefficients and SEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:38<00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'point_estimate': array([-2.73682294e-04, -4.39868205e-04,  9.99347122e-01, -9.99443294e-01,\n",
      "        1.00003536e+00,  1.00006450e+00,  2.00006685e+00,  1.99995671e+00]), 'standard_error': array([6.70325435e-04, 4.15857348e-04, 7.26599979e-04, 4.45407815e-04,\n",
      "       4.67005434e-05, 4.95007891e-05, 3.96508809e-05, 3.66987192e-05])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m2 = DuckRegression(\n",
    "    db_name=\"large_dataset.db\",\n",
    "    table_name=\"data\",\n",
    "    formula=\"Y + Y2 ~ D + f1 + f2\",\n",
    "    cluster_col=\"f1\",\n",
    "    n_bootstraps=100,\n",
    "    seed=232,\n",
    ")\n",
    "\n",
    "m2.fit()\n",
    "print(results := m2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compressed data contains summary stats on all outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>count</th>\n",
       "      <th>sum_Y</th>\n",
       "      <th>sum_Y2</th>\n",
       "      <th>sum_Y_sq</th>\n",
       "      <th>sum_Y2_sq</th>\n",
       "      <th>mean_Y</th>\n",
       "      <th>mean_Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12395</td>\n",
       "      <td>235463.726925</td>\n",
       "      <td>210700.599740</td>\n",
       "      <td>4.485553e+06</td>\n",
       "      <td>3.594147e+06</td>\n",
       "      <td>18.996670</td>\n",
       "      <td>16.998838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12351</td>\n",
       "      <td>271683.595444</td>\n",
       "      <td>271604.033443</td>\n",
       "      <td>5.988431e+06</td>\n",
       "      <td>5.984957e+06</td>\n",
       "      <td>21.996891</td>\n",
       "      <td>21.990449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12579</td>\n",
       "      <td>515509.114135</td>\n",
       "      <td>490622.027746</td>\n",
       "      <td>2.113883e+07</td>\n",
       "      <td>1.914848e+07</td>\n",
       "      <td>40.981725</td>\n",
       "      <td>39.003262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12484</td>\n",
       "      <td>75037.646656</td>\n",
       "      <td>74873.009753</td>\n",
       "      <td>4.634795e+05</td>\n",
       "      <td>4.614652e+05</td>\n",
       "      <td>6.010705</td>\n",
       "      <td>5.997518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12159</td>\n",
       "      <td>656632.641213</td>\n",
       "      <td>632393.029916</td>\n",
       "      <td>3.547280e+07</td>\n",
       "      <td>3.290315e+07</td>\n",
       "      <td>54.003836</td>\n",
       "      <td>52.010283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12495</td>\n",
       "      <td>237397.967083</td>\n",
       "      <td>212456.025869</td>\n",
       "      <td>4.522934e+06</td>\n",
       "      <td>3.625122e+06</td>\n",
       "      <td>18.999437</td>\n",
       "      <td>17.003283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12424</td>\n",
       "      <td>633597.411975</td>\n",
       "      <td>633524.976810</td>\n",
       "      <td>3.232453e+07</td>\n",
       "      <td>3.231684e+07</td>\n",
       "      <td>50.997860</td>\n",
       "      <td>50.992030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12648</td>\n",
       "      <td>531095.342089</td>\n",
       "      <td>531232.048632</td>\n",
       "      <td>2.231381e+07</td>\n",
       "      <td>2.232497e+07</td>\n",
       "      <td>41.990460</td>\n",
       "      <td>42.001269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12622</td>\n",
       "      <td>517589.531971</td>\n",
       "      <td>492104.093359</td>\n",
       "      <td>2.123756e+07</td>\n",
       "      <td>1.919859e+07</td>\n",
       "      <td>41.006935</td>\n",
       "      <td>38.987806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12417</td>\n",
       "      <td>496594.626304</td>\n",
       "      <td>471878.145612</td>\n",
       "      <td>1.987264e+07</td>\n",
       "      <td>1.794501e+07</td>\n",
       "      <td>39.993124</td>\n",
       "      <td>38.002589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       D    f1    f2  count          sum_Y         sum_Y2      sum_Y_sq  \\\n",
       "0    1.0  16.0   1.0  12395  235463.726925  210700.599740  4.485553e+06   \n",
       "1    0.0   8.0   7.0  12351  271683.595444  271604.033443  5.988431e+06   \n",
       "2    1.0  12.0  14.0  12579  515509.114135  490622.027746  2.113883e+07   \n",
       "3    0.0   0.0   3.0  12484   75037.646656   74873.009753  4.634795e+05   \n",
       "4    1.0  17.0  18.0  12159  656632.641213  632393.029916  3.547280e+07   \n",
       "..   ...   ...   ...    ...            ...            ...           ...   \n",
       "795  1.0   8.0   5.0  12495  237397.967083  212456.025869  4.522934e+06   \n",
       "796  0.0  13.0  19.0  12424  633597.411975  633524.976810  3.232453e+07   \n",
       "797  0.0  14.0  14.0  12648  531095.342089  531232.048632  2.231381e+07   \n",
       "798  1.0  14.0  13.0  12622  517589.531971  492104.093359  2.123756e+07   \n",
       "799  1.0  15.0  12.0  12417  496594.626304  471878.145612  1.987264e+07   \n",
       "\n",
       "        sum_Y2_sq     mean_Y    mean_Y2  \n",
       "0    3.594147e+06  18.996670  16.998838  \n",
       "1    5.984957e+06  21.996891  21.990449  \n",
       "2    1.914848e+07  40.981725  39.003262  \n",
       "3    4.614652e+05   6.010705   5.997518  \n",
       "4    3.290315e+07  54.003836  52.010283  \n",
       "..            ...        ...        ...  \n",
       "795  3.625122e+06  18.999437  17.003283  \n",
       "796  3.231684e+07  50.997860  50.992030  \n",
       "797  2.232497e+07  41.990460  42.001269  \n",
       "798  1.919859e+07  41.006935  38.987806  \n",
       "799  1.794501e+07  39.993124  38.002589  \n",
       "\n",
       "[800 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.df_compressed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output needs some post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept_Y</th>\n",
       "      <td>-0.000274</td>\n",
       "      <td>0.000670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intercept_Y2</th>\n",
       "      <td>-0.000440</td>\n",
       "      <td>0.000416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_Y</th>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.000727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_Y2</th>\n",
       "      <td>-0.999443</td>\n",
       "      <td>0.000445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_Y</th>\n",
       "      <td>1.000035</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_Y2</th>\n",
       "      <td>1.000064</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2_Y</th>\n",
       "      <td>2.000067</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2_Y2</th>\n",
       "      <td>1.999957</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              point_estimate  standard_error\n",
       "Intercept_Y        -0.000274        0.000670\n",
       "Intercept_Y2       -0.000440        0.000416\n",
       "D_Y                 0.999347        0.000727\n",
       "D_Y2               -0.999443        0.000445\n",
       "f1_Y                1.000035        0.000047\n",
       "f1_Y2               1.000064        0.000050\n",
       "f2_Y                2.000067        0.000040\n",
       "f2_Y2               1.999957        0.000037"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restab = pd.DataFrame(\n",
    "    np.c_[results[\"point_estimate\"], results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    "    index=[f\"{x}_{y}\" for x in [\"Intercept\", \"D\", \"f1\", \"f2\"] for y in [\"Y\", \"Y2\"]],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panel Data\n",
    "\n",
    "We have specialised estimators for panel data with N >> T, where the conventional compressed approach is inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_panel(\n",
    "    # Parameters\n",
    "    N=1_000_000,\n",
    "    T=35,  # Number of units and time periods\n",
    "    T0=5,  # Treatment starts at T0\n",
    "    tau=0.005,\n",
    "    sigma_list=[5, 2, 0.01, 2],\n",
    "    seed=42,\n",
    "):\n",
    "    np.random.seed(seed)\n",
    "    sigma_unit, sigma_time, sigma_tt, sigma_e = sigma_list\n",
    "    # Generate data\n",
    "    unit_ids = np.repeat(np.arange(N), T)\n",
    "    time_ids = np.tile(np.arange(T), N)\n",
    "\n",
    "    # Generate unit-specific intercepts and time trends\n",
    "    unit_fe = np.random.normal(0, sigma_unit, N)\n",
    "    time_fe = np.random.normal(\n",
    "        0, sigma_time, T\n",
    "    )  # Common shocks for all units at each time period\n",
    "    unit_tt = np.random.normal(0, sigma_tt, N)\n",
    "\n",
    "    # Generate treatment indicator (randomly assigned)\n",
    "    W = np.random.binomial(1, 0.5, N)\n",
    "    W = np.repeat(W, T)\n",
    "    W = W * (time_ids >= T0)\n",
    "\n",
    "    rho = 0.7  # Autoregressive parameter for residuals\n",
    "    # Generate serially correlated residuals for each unit (optimized version)\n",
    "    residuals = np.zeros((N, T))\n",
    "    residuals[:, 0] = np.random.normal(0, sigma_e, N)\n",
    "    epsilon = np.random.normal(0, 1, (N, T - 1))\n",
    "    factor = 0.5 * np.sqrt(1 - rho**2)\n",
    "    for t in range(1, T):\n",
    "        residuals[:, t] = rho * residuals[:, t - 1] + factor * epsilon[:, t - 1]\n",
    "    # iid\n",
    "    # residuals = np.random.normal(0, 0.5, N*T)\n",
    "\n",
    "    # Generate outcome\n",
    "    Y = (\n",
    "        np.repeat(unit_fe, T)\n",
    "        + np.repeat(unit_tt, T) * time_ids\n",
    "        + tau * W  # Treatment effect is 1\n",
    "        + np.tile(time_fe, N)  # time FE\n",
    "        + residuals.flatten()\n",
    "    )  # Individual noise\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\"unit\": unit_ids, \"time\": time_ids, \"Y\": Y, \"W\": W})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = sim_panel(tau=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name, table_name = \"panel_data.db\", \"panel_data\"\n",
    "# write to database\n",
    "conn = duckdb.connect(db_name)\n",
    "conn.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "conn.execute(f\"CREATE TABLE {table_name} AS SELECT * from df\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peek at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unit  time         Y  W\n",
      "0     0     0  3.096240  0\n",
      "1     0     1  2.656935  0\n",
      "2     0     2  5.084101  0\n",
      "3     0     3  3.274999  0\n",
      "4     0     4  4.638763  0\n"
     ]
    }
   ],
   "source": [
    "conn = duckdb.connect(db_name)\n",
    "print(conn.execute(\"SELECT * FROM panel_data LIMIT 5\").fetchdf())\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckreg.estimators import DuckMundlak, DuckDoubleDemeaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mundlak\n",
    "\n",
    "\n",
    "One-way mundlak \n",
    "\n",
    "$$\n",
    "Y_{it} = \\alpha + \\beta X_{it} + \\gamma \\bar{X}_{i} + \\epsilon_{it}\n",
    "$$\n",
    "\n",
    "Two-way mundlak\n",
    "\n",
    "$$\n",
    "Y_{it} = \\alpha + \\beta X_{it} + \\gamma \\bar{X}_{i, \\cdot} + \\delta \\bar{X}_{\\cdot, t} + \\epsilon_{it}\n",
    "$$\n",
    "\n",
    "both of which can be compressed easily with `duckdb`.\n",
    "\n",
    "These representations are much more efficient than the above general procedure because the unit and time fixed effects are typically very high dimensional, but covariate averages are not. Also see [Arkhangelsky and Imbens](https://arxiv.org/abs/1807.02099) on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:35<00:00,  1.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.896134</td>\n",
       "      <td>0.005633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.003877</td>\n",
       "      <td>0.001765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009106</td>\n",
       "      <td>0.009642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.413955</td>\n",
       "      <td>0.002209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_estimate  standard_error\n",
       "0        0.896134        0.005633\n",
       "1        1.003877        0.001765\n",
       "2        0.009106        0.009642\n",
       "3       -2.413955        0.002209"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mundlak = DuckMundlak(\n",
    "    db_name=\"panel_data.db\",\n",
    "    table_name=\"panel_data\",\n",
    "    outcome_var=\"Y\",\n",
    "    covariates=[\"W\"],\n",
    "    unit_col=\"unit\",\n",
    "    time_col=\"time\",\n",
    "    cluster_col=\"unit\",\n",
    "    n_bootstraps=50,\n",
    "    seed=929,\n",
    ")\n",
    "mundlak.fit()\n",
    "\n",
    "mundlak_results = mundlak.summary()\n",
    "\n",
    "restab = pd.DataFrame(\n",
    "    np.c_[mundlak_results[\"point_estimate\"], mundlak_results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powered by the following sequence of queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        CREATE TEMP TABLE unit_avgs AS\n",
      "        SELECT unit,\n",
      "               AVG(W) AS avg_W_unit\n",
      "        FROM panel_data\n",
      "        GROUP BY unit\n",
      "        \n",
      "\n",
      "            CREATE TEMP TABLE time_avgs AS\n",
      "            SELECT time,\n",
      "                   AVG(W) AS avg_W_time\n",
      "            FROM panel_data\n",
      "            GROUP BY time\n",
      "            \n",
      "\n",
      "        CREATE TEMP TABLE design_matrix AS\n",
      "        SELECT\n",
      "            t.unit,\n",
      "            t.time,\n",
      "            t.Y,\n",
      "            t.W,\n",
      "            u.avg_W_unit\n",
      "            , tm.avg_W_time\n",
      "        FROM panel_data t\n",
      "        JOIN unit_avgs u ON t.unit = u.unit\n",
      "        JOIN time_avgs tm ON t.time = tm.time\n",
      "        \n",
      "\n",
      "        SELECT\n",
      "            W, avg_W_unit, avg_W_time,\n",
      "            COUNT(*) as count,\n",
      "            SUM(Y) as sum_Y\n",
      "        FROM design_matrix\n",
      "        GROUP BY W, avg_W_unit, avg_W_time\n",
      "        \n",
      "\n",
      "            SELECT\n",
      "                W,\n",
      "                avg_W_unit\n",
      "                , avg_W_time,\n",
      "                COUNT(*) as count,\n",
      "                SUM(Y) as sum_Y\n",
      "            FROM design_matrix\n",
      "            WHERE unit IN (SELECT unnest((?)))\n",
      "            GROUP BY W,\n",
      "                        avg_W_unit\n",
      "                        , avg_W_time\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(mundlak.unit_avg_query)\n",
    "print(mundlak.time_avg_query)\n",
    "print(mundlak.design_matrix_query)\n",
    "print(mundlak.compress_query)\n",
    "print(mundlak.bootstrap_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Demeaning\n",
    "\n",
    "$$\n",
    "Y_{it} = \\alpha + \\ddot{X}_{it} \\beta + \\epsilon_{it}\n",
    "$$\n",
    "\n",
    "where $\\ddot{X}_{it} = X_{it} - \\bar{X}_{i, \\cdot} - \\bar{X}_{\\cdot, t} + \\bar{X}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:44<00:00,  1.64s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.295524</td>\n",
       "      <td>0.003857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.003877</td>\n",
       "      <td>0.002097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_estimate  standard_error\n",
       "0        0.295524        0.003857\n",
       "1        1.003877        0.002097"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_demean = DuckDoubleDemeaning(\n",
    "    db_name=\"panel_data.db\",\n",
    "    table_name=\"panel_data\",\n",
    "    outcome_var=\"Y\",\n",
    "    treatment_var=\"W\",\n",
    "    unit_col=\"unit\",\n",
    "    time_col=\"time\",\n",
    "    cluster_col=\"unit\",\n",
    "    n_bootstraps=100,\n",
    "    seed=828,\n",
    ")\n",
    "\n",
    "double_demean.fit()\n",
    "\n",
    "dd_results = double_demean.summary()\n",
    "\n",
    "restab = pd.DataFrame(\n",
    "    np.c_[dd_results[\"point_estimate\"], dd_results[\"standard_error\"]],\n",
    "    columns=[\"point_estimate\", \"standard_error\"],\n",
    ")\n",
    "restab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        CREATE TEMP TABLE overall_mean AS\n",
      "        SELECT AVG(W) AS mean_W\n",
      "        FROM panel_data\n",
      "        \n",
      "\n",
      "        CREATE TEMP TABLE unit_means AS\n",
      "        SELECT unit, AVG(W) AS mean_W_unit\n",
      "        FROM panel_data\n",
      "        GROUP BY unit\n",
      "        \n",
      "\n",
      "        CREATE TEMP TABLE time_means AS\n",
      "        SELECT time, AVG(W) AS mean_W_time\n",
      "        FROM panel_data\n",
      "        GROUP BY time\n",
      "        \n",
      "\n",
      "        CREATE TEMP TABLE double_demeaned AS\n",
      "        SELECT\n",
      "            t.unit,\n",
      "            t.time,\n",
      "            t.Y,\n",
      "            t.W - um.mean_W_unit - tm.mean_W_time + om.mean_W AS ddot_W\n",
      "        FROM panel_data t\n",
      "        JOIN unit_means um ON t.unit = um.unit\n",
      "        JOIN time_means tm ON t.time = tm.time\n",
      "        CROSS JOIN overall_mean om\n",
      "        \n",
      "\n",
      "        SELECT\n",
      "            ddot_W,\n",
      "            COUNT(*) as count,\n",
      "            SUM(Y) as sum_Y\n",
      "        FROM double_demeaned\n",
      "        GROUP BY ddot_W\n",
      "        \n",
      "\n",
      "            SELECT\n",
      "                ddot_W,\n",
      "                COUNT(*) as count,\n",
      "                SUM(Y) as sum_Y\n",
      "            FROM double_demeaned\n",
      "            WHERE unit IN (SELECT unnest((?)))\n",
      "            GROUP BY ddot_W\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(double_demean.overall_mean_query)\n",
    "print(double_demean.unit_mean_query)\n",
    "print(double_demean.time_mean_query)\n",
    "print(double_demean.double_demean_query)\n",
    "print(double_demean.compress_query)\n",
    "print(double_demean.bootstrap_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
