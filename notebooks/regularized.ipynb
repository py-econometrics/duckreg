{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda97b40",
   "metadata": {},
   "source": [
    "# Compressed Ridge Regression \n",
    "\n",
    "Comparison with scikit-learn\n",
    "\n",
    "Ridge is computable in closed-form using normal equations:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} = (X^TX + \\lambda I)^{-1}X^\\top y\n",
    "$$\n",
    "\n",
    "We can also show [[ESL](https://hastie.su.domains/ElemStatLearn/) Chapter 3 problem 3.12] that we can solve ridge with the following design matrix\n",
    "\n",
    "$$\n",
    "\\widetilde{X} = \\begin{bmatrix} X \\\\ \\sqrt{\\lambda} I \\end{bmatrix} \n",
    "$$\n",
    "\n",
    "and response vector\n",
    "$$\n",
    "\\widetilde{y} = \\begin{bmatrix} y \\\\ 0_{p \\times s1} \\end{bmatrix} \n",
    "$$\n",
    "\n",
    "where $I$ is the identity matrix and $0_{p \\times 1}$ is a vector of zeros of length $p$ (the number of features). This lets us use optimized OLS routines that don't require brittle matrix inversions.\n",
    "Importantly, we can use the same trick for compression as OLS used in the rest of the package to solve ridge regression.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75dbde4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import time\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from duckreg.regularized import DuckRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98c6abd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_large_dataset(N=1_000_000, seed=42):\n",
    "    \"\"\"Generate large synthetic dataset with discrete covariates\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Create discrete covariates (similar to introduction.ipynb)\n",
    "    D = rng.choice([0, 1], size=(N, 1))\n",
    "    f1 = rng.choice(range(3), (N, 1), True)\n",
    "    f2 = rng.choice(range(4), (N, 1), True)\n",
    "    f3 = rng.choice(range(2), (N, 1), True)\n",
    "\n",
    "    # True coefficients\n",
    "    beta_D, beta_f1, beta_f2, beta_f3 = 1.0, 2.0, 1.5, 0.8\n",
    "\n",
    "    # Generate outcome with some noise\n",
    "    Y = (\n",
    "        beta_D * D\n",
    "        + beta_f1 * f1\n",
    "        + beta_f2 * f2\n",
    "        + beta_f3 * f3\n",
    "        + rng.normal(size=(N, 1))\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        np.concatenate([Y, D, f1, f2, f3], axis=1), columns=[\"Y\", \"D\", \"f1\", \"f2\", \"f3\"]\n",
    "    ).assign(rowid=range(N))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_duckdb_database(df, db_name=\"ridge_test.db\", table=\"data\"):\n",
    "    \"\"\"Create and populate DuckDB database\"\"\"\n",
    "    conn = duckdb.connect(db_name)\n",
    "    conn.execute(f\"DROP TABLE IF EXISTS {table}\")\n",
    "    conn.execute(f\"CREATE TABLE {table} AS SELECT * FROM df\")\n",
    "    conn.close()\n",
    "    print(f\"Data loaded into DuckDB database: {db_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b4494f",
   "metadata": {},
   "source": [
    "### compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff549e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPRESSION EFFECTIVENESS TEST\n",
      "============================================================\n",
      "Data loaded into DuckDB database: compression_test.db\n",
      "Original dataset size: 1,000,000 rows\n",
      "Compressed dataset size: 48 rows\n",
      "Compression ratio: 20833.3x\n",
      "\n",
      "Sample compressed data:\n",
      "     D   f1   f2   f3  count          sum_Y      sum_Y_sq    mean_Y\n",
      "0  0.0  2.0  2.0  0.0  21051  147248.222708  1.051406e+06  6.994833\n",
      "1  1.0  1.0  3.0  1.0  20994  174254.435303  1.467337e+06  8.300202\n",
      "2  1.0  0.0  0.0  1.0  20731   37076.464020  8.696013e+04  1.788455\n",
      "3  0.0  0.0  2.0  0.0  20835   62760.170740  2.095595e+05  3.012247\n",
      "4  0.0  1.0  2.0  1.0  20551  119114.771163  7.103898e+05  5.796057\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test how much compression we achieve\"\"\"\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPRESSION EFFECTIVENESS TEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df = generate_large_dataset(N=1_000_000, seed=42)\n",
    "db_name = \"compression_test.db\"\n",
    "create_duckdb_database(df, db_name)\n",
    "\n",
    "# Check compressed data size\n",
    "duck_ridge = DuckRidge(\n",
    "    db_name=db_name,\n",
    "    table_name=\"data\",\n",
    "    formula=\"Y ~ D + f1 + f2 + f3\",\n",
    "    cv_folds=1,\n",
    "    seed=42,\n",
    ")\n",
    "duck_ridge.prepare_data()\n",
    "duck_ridge.compress_data()\n",
    "\n",
    "original_size = len(df)\n",
    "compressed_size = len(duck_ridge.df_compressed)\n",
    "compression_ratio = original_size / compressed_size\n",
    "\n",
    "print(f\"Original dataset size: {original_size:,} rows\")\n",
    "print(f\"Compressed dataset size: {compressed_size:,} rows\")\n",
    "print(f\"Compression ratio: {compression_ratio:.1f}x\")\n",
    "\n",
    "print(f\"\\nSample compressed data:\")\n",
    "print(duck_ridge.df_compressed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef220ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DUCKRIDGE VS SKLEARN RIDGE COMPARISON\n",
      "============================================================\n",
      "Generating synthetic dataset...\n",
      "Data loaded into DuckDB database: ridge_test.db\n",
      "Dataset shape: (50000000, 6)\n",
      "Sample data:\n",
      "           Y    D   f1   f2   f3  rowid\n",
      "0  -0.829123  0.0  0.0  0.0  1.0      0\n",
      "1  11.229651  1.0  2.0  3.0  0.0      1\n",
      "2   8.225920  1.0  2.0  2.0  1.0      2\n",
      "3   3.200686  0.0  0.0  2.0  1.0      3\n",
      "4   2.910670  0.0  0.0  2.0  0.0      4\n",
      "\n",
      "\n",
      "--- Testing λ = 1e-05 ---\n",
      "Running DuckRidge...\n",
      "DuckRidge time: 1.233 seconds\n",
      "DuckRidge coefficients: [-7.74916894e-04  9.99730350e-01  2.00020894e+00  1.50020680e+00\n",
      "  8.00456521e-01]\n",
      "Running sklearn Ridge...\n",
      "Sklearn time: 6.934 seconds\n",
      "Sklearn coefficients: [-7.74916894e-04  9.99730350e-01  2.00020894e+00  1.50020680e+00\n",
      "  8.00456521e-01]\n",
      "Speedup: 5.6x\n",
      "\n",
      "--- Testing λ = 0.0004641588833612782 ---\n",
      "Running DuckRidge...\n",
      "DuckRidge time: 1.353 seconds\n",
      "DuckRidge coefficients: [-7.74916818e-04  9.99730350e-01  2.00020894e+00  1.50020680e+00\n",
      "  8.00456521e-01]\n",
      "Running sklearn Ridge...\n",
      "Sklearn time: 5.592 seconds\n",
      "Sklearn coefficients: [-7.74916818e-04  9.99730350e-01  2.00020894e+00  1.50020680e+00\n",
      "  8.00456521e-01]\n",
      "Speedup: 4.1x\n",
      "\n",
      "--- Testing λ = 0.021544346900318846 ---\n",
      "Running DuckRidge...\n",
      "DuckRidge time: 1.201 seconds\n",
      "DuckRidge coefficients: [-7.74913273e-04  9.99730348e-01  2.00020894e+00  1.50020680e+00\n",
      "  8.00456519e-01]\n",
      "Running sklearn Ridge...\n",
      "Sklearn time: 5.374 seconds\n",
      "Sklearn coefficients: [-7.74913276e-04  9.99730348e-01  2.00020894e+00  1.50020680e+00\n",
      "  8.00456519e-01]\n",
      "Speedup: 4.5x\n",
      "\n",
      "--- Testing λ = 1.0 ---\n",
      "Running DuckRidge...\n",
      "DuckRidge time: 1.189 seconds\n",
      "DuckRidge coefficients: [-7.74748767e-04  9.99730270e-01  2.00020888e+00  1.50020677e+00\n",
      "  8.00456456e-01]\n",
      "Running sklearn Ridge...\n",
      "Sklearn time: 5.397 seconds\n",
      "Sklearn coefficients: [-7.74748865e-04  9.99730270e-01  2.00020888e+00  1.50020678e+00\n",
      "  8.00456457e-01]\n",
      "Speedup: 4.5x\n",
      "\n",
      "--- Testing λ = 46.41588833612782 ---\n",
      "Running DuckRidge...\n",
      "DuckRidge time: 1.226 seconds\n",
      "DuckRidge coefficients: [-7.67113122e-04  9.99726637e-01  2.00020615e+00  1.50020568e+00\n",
      "  8.00453546e-01]\n",
      "Running sklearn Ridge...\n",
      "Sklearn time: 5.092 seconds\n",
      "Sklearn coefficients: [-7.67117609e-04  9.99726639e-01  2.00020615e+00  1.50020568e+00\n",
      "  8.00453548e-01]\n",
      "Speedup: 4.2x\n",
      "\n",
      "--- Testing λ = 2154.4346900318865 ---\n",
      "Running DuckRidge...\n",
      "DuckRidge time: 1.226 seconds\n",
      "DuckRidge coefficients: [-4.12830954e-04  9.99558072e-01  2.00007961e+00  1.50015506e+00\n",
      "  8.00318529e-01]\n",
      "Running sklearn Ridge...\n",
      "Sklearn time: 5.806 seconds\n",
      "Sklearn coefficients: [-4.12943026e-04  9.99558108e-01  2.00007964e+00  1.50015508e+00\n",
      "  8.00318565e-01]\n",
      "Speedup: 4.7x\n",
      "\n",
      "--- Testing λ = 100000.0 ---\n",
      "Running DuckRidge...\n",
      "DuckRidge time: 1.323 seconds\n",
      "DuckRidge coefficients: [0.01574958 0.99186013 1.99427225 1.49784793 0.79416544]\n",
      "Running sklearn Ridge...\n",
      "Sklearn time: 5.231 seconds\n",
      "Sklearn coefficients: [0.01594732 0.99179765 1.99422514 1.49781018 0.79410291]\n",
      "Speedup: 4.0x\n",
      "\n",
      "--- Testing λ = 4641588.833612791 ---\n",
      "Running DuckRidge...\n",
      "DuckRidge time: 1.197 seconds\n",
      "DuckRidge coefficients: [0.42697409 0.78685586 1.80788334 1.44077618 0.64151136]\n",
      "Running sklearn Ridge...\n",
      "Sklearn time: 4.996 seconds\n",
      "Sklearn coefficients: [0.64304671 0.72906626 1.75569294 1.39649413 0.58367285]\n",
      "Speedup: 4.2x\n",
      "\n",
      "--- Testing λ = 215443469.00318867 ---\n",
      "Running DuckRidge...\n",
      "DuckRidge time: 1.217 seconds\n",
      "DuckRidge coefficients: [0.5155682  0.29845858 0.71443635 0.93688302 0.28757603]\n",
      "Running sklearn Ridge...\n",
      "Sklearn time: 5.111 seconds\n",
      "Sklearn coefficients: [4.32658525 0.0548375  0.26798607 0.33736111 0.04384859]\n",
      "Speedup: 4.2x\n",
      "\n",
      "--- Testing λ = 10000000000.0 ---\n",
      "Running DuckRidge...\n",
      "DuckRidge time: 1.197 seconds\n",
      "DuckRidge coefficients: [0.02504854 0.01375608 0.0316078  0.04666283 0.01350963]\n",
      "Running sklearn Ridge...\n",
      "Sklearn time: 5.692 seconds\n",
      "Sklearn coefficients: [5.12825224e+00 1.24847515e-03 6.64471852e-03 9.31863773e-03\n",
      " 9.97955178e-04]\n",
      "Speedup: 4.8x\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Compare DuckRidge vs sklearn Ridge performance\"\"\"\n",
    "print(\"=\" * 60)\n",
    "print(\"DUCKRIDGE VS SKLEARN RIDGE COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate data\n",
    "print(\"Generating synthetic dataset...\")\n",
    "df = generate_large_dataset(N=50_000_000, seed=42)\n",
    "db_name = \"ridge_test.db\"\n",
    "create_duckdb_database(df, db_name)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Sample data:\\n{df.head()}\\n\")\n",
    "\n",
    "# Test different lambda values\n",
    "lambda_values = np.logspace(-5, 10, 10)\n",
    "\n",
    "for lam in lambda_values:\n",
    "    print(f\"\\n--- Testing λ = {lam} ---\")\n",
    "\n",
    "    # DuckRidge\n",
    "    print(\"Running DuckRidge...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    duck_ridge = DuckRidge(\n",
    "        db_name=db_name,\n",
    "        table_name=\"data\",\n",
    "        formula=\"Y ~ D + f1 + f2 + f3\",\n",
    "        lambda_grid=[lam],  # Single lambda for fair comparison\n",
    "        cv_folds=1,  # No CV for speed\n",
    "        seed=42,\n",
    "    )\n",
    "    duck_ridge.fit(lambda_selection=\"single\")\n",
    "    duck_time = time.time() - start_time\n",
    "    duck_coefs = duck_ridge.point_estimate\n",
    "\n",
    "    print(f\"DuckRidge time: {duck_time:.3f} seconds\")\n",
    "    print(f\"DuckRidge coefficients: {duck_coefs}\")\n",
    "\n",
    "    # Sklearn Ridge (on full data)\n",
    "    print(\"Running sklearn Ridge...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Prepare sklearn data\n",
    "    X_sklearn = df[[\"D\", \"f1\", \"f2\", \"f3\"]].values\n",
    "    y_sklearn = df[\"Y\"].values\n",
    "\n",
    "    sklearn_ridge = Ridge(alpha=lam, fit_intercept=True, solver=\"svd\")\n",
    "    sklearn_ridge.fit(X_sklearn, y_sklearn)\n",
    "    sklearn_time = time.time() - start_time\n",
    "\n",
    "    sklearn_coefs = np.concatenate([[sklearn_ridge.intercept_], sklearn_ridge.coef_])\n",
    "\n",
    "    print(f\"Sklearn time: {sklearn_time:.3f} seconds\")\n",
    "    print(f\"Sklearn coefficients: {sklearn_coefs}\")\n",
    "\n",
    "    # Compare results\n",
    "    speedup = sklearn_time / duck_time\n",
    "    coef_diff = np.abs(duck_coefs - sklearn_coefs)\n",
    "    max_diff = np.max(coef_diff)\n",
    "\n",
    "    print(f\"Speedup: {speedup:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2986c67",
   "metadata": {},
   "source": [
    "The penalization factor $\\lambda$ is scaled differently in the compressed form, so the coefficients are not identical across the two methods for a given $\\lambda$. However, for a sufficiently fine grid of $\\lambda$ values, we can still find the optimal $\\lambda$ that minimizes the cross-validated error, where compression yields even greater speedups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3472f2",
   "metadata": {},
   "source": [
    "### cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85796398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DUCKRIDGE CROSS-VALIDATION TEST\n",
      "============================================================\n",
      "Generating dataset for CV test...\n",
      "Data loaded into DuckDB database: ridge_cv_test.db\n",
      "Running cross-validation...\n",
      "CV time: 2.159 seconds\n",
      "Best lambda: 2.335721\n",
      "Best coefficients: [1.10838176e-03 9.99475426e-01 1.99977411e+00 1.49963835e+00\n",
      " 8.00333145e-01]\n",
      "\n",
      "Running sklearn RidgeCV...\n",
      "Sklearn CV time: 61.325 seconds\n",
      "Sklearn best alpha: 3.792690\n",
      "Sklearn coefficients: [1.10960621e-03 9.99474844e-01 1.99977367e+00 1.49963817e+00\n",
      " 8.00332678e-01]\n",
      "CV Speedup: 28.4x\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test DuckRidge cross-validation\"\"\"\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DUCKRIDGE CROSS-VALIDATION TEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use smaller dataset for CV demo\n",
    "print(\"Generating dataset for CV test...\")\n",
    "df = generate_large_dataset(N=10_000_000, seed=42)\n",
    "db_name = \"ridge_cv_test.db\"\n",
    "create_duckdb_database(df, db_name)\n",
    "\n",
    "# Test CV with lambda grid\n",
    "print(\"Running cross-validation...\")\n",
    "start_time = time.time()\n",
    "\n",
    "duck_ridge_cv = DuckRidge(\n",
    "    db_name=db_name,\n",
    "    table_name=\"data\",\n",
    "    formula=\"Y ~ D + f1 + f2 + f3\",\n",
    "    lambda_grid=np.logspace(-3, 1, 20),  # 20 lambda values\n",
    "    cv_folds=5,\n",
    "    seed=42,\n",
    ")\n",
    "duck_ridge_cv.fit(lambda_selection=\"cv\")\n",
    "cv_time = time.time() - start_time\n",
    "\n",
    "print(f\"CV time: {cv_time:.3f} seconds\")\n",
    "print(f\"Best lambda: {duck_ridge_cv.best_lambda:.6f}\")\n",
    "print(f\"Best coefficients: {duck_ridge_cv.point_estimate}\")\n",
    "\n",
    "# Compare with sklearn RidgeCV\n",
    "print(\"\\nRunning sklearn RidgeCV...\")\n",
    "start_time = time.time()\n",
    "\n",
    "X_sklearn = df[[\"D\", \"f1\", \"f2\", \"f3\"]].values\n",
    "y_sklearn = df[\"Y\"].values\n",
    "\n",
    "sklearn_ridge_cv = RidgeCV(alphas=np.logspace(-3, 1, 20), cv=5, fit_intercept=True)\n",
    "sklearn_ridge_cv.fit(X_sklearn, y_sklearn)\n",
    "sklearn_cv_time = time.time() - start_time\n",
    "\n",
    "sklearn_cv_coefs = np.concatenate(\n",
    "    [[sklearn_ridge_cv.intercept_], sklearn_ridge_cv.coef_]\n",
    ")\n",
    "\n",
    "print(f\"Sklearn CV time: {sklearn_cv_time:.3f} seconds\")\n",
    "print(f\"Sklearn best alpha: {sklearn_ridge_cv.alpha_:.6f}\")\n",
    "print(f\"Sklearn coefficients: {sklearn_cv_coefs}\")\n",
    "\n",
    "cv_speedup = sklearn_cv_time / cv_time\n",
    "print(f\"CV Speedup: {cv_speedup:.1f}x\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
